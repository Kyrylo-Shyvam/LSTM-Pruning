{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!git clone -b experiments https://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@github.com/Kyrylo-Shyvam/LSTM-Pruning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "%cd ./LSTM-Pruning/code\n",
    "!ls\n",
    "!ls ./work_dir/\n",
    "import wandb\n",
    "import lstmModel\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_src = utils.read_corpus(\"./data/valid.de-en.de\", source='src')\n",
    "dev_data_tgt = utils.read_corpus(\"./data/valid.de-en.en\", source='tgt')\n",
    "dev_data = list(zip(dev_data_src, dev_data_tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=\"14dded5f079435f64fb5e2f0278662dda5605f9e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['src_emb','tgt_emb','encoder','linear1','decoder','softmax','dropout','linear2','attention','label_smoothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_uniform_sub(module,percentage):\n",
    "    layers=[]\n",
    "    for weight_name,_ in module.named_parameters():\n",
    "        layers.append([module,weight_name])\n",
    "    if len(layers) > 0:\n",
    "        prune.global_unstructured(layers,pruning_method=prune.L1Unstructured,amount=percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_distribution_sub(module, lamb):\n",
    "    layers=[]\n",
    "    for weight_name,_ in module.named_parameters():\n",
    "        layers.append([module,weight_name])\n",
    "    if len(layers) == 0:\n",
    "        return 0,0\n",
    "    params=[]\n",
    "    for param in module.parameters():\n",
    "        params.append(param.flatten())\n",
    "    params=torch.cat(params)\n",
    "    std=params.std()\n",
    "    cnt=(lamb*std > abs(params)).float().sum().int().item()\n",
    "    prune.global_unstructured(layers,pruning_method=prune.L1Unstructured,amount=cnt)\n",
    "    return cnt, params.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num(model):\n",
    "    arr = []\n",
    "    for i in model.parameters():\n",
    "        arr.append(i.flatten())\n",
    "    arr = torch.cat(arr)\n",
    "    a=torch.topk(abs(arr),int(0.1*len(arr)), sorted=True)\n",
    "    print(a[0].shape,arr.shape)\n",
    "    return a[0][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_blind_sub(module, num):\n",
    "    layers=[]\n",
    "    for weight_name,_ in module.named_parameters():\n",
    "        layers.append([module,weight_name])\n",
    "    if len(layers) == 0:\n",
    "        return 0,0\n",
    "    params=[]\n",
    "    for param in module.parameters():\n",
    "        params.append(param.flatten())\n",
    "    params=torch.cat(params)\n",
    "    cnt=(num > abs(params)).int().sum().item()\n",
    "    prune.global_unstructured(layers,pruning_method=prune.L1Unstructured,amount=cnt)\n",
    "    return cnt, params.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_a=tot_b=0\n",
    "model=lstmModel.NMT.load('./work_dir/model0.bin')\n",
    "magic_num = get_num(model)\n",
    "magic_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(10):\n",
    "    wandb.init(project=\"percentage-pruned-per-layer\")\n",
    "    wandb.config.className = labels[k]\n",
    "    wandb.config.model='model0'\n",
    "    wandb.config.pruning_type='class-d'\n",
    "    model=lstmModel.NMT.load('./work_dir/model0.bin')\n",
    "    model.to('cuda:0')\n",
    "    children=[]\n",
    "    for i,j in model.named_children():\n",
    "        children.append(j)\n",
    "#         print(j)\n",
    "    a,b=class_distribution_sub(children[k], 1.63)\n",
    "    if b>0:\n",
    "        print(a/b)\n",
    "        wandb.log({\"percentage_pruned\":a/b})\n",
    "    else:\n",
    "        print(a,b)\n",
    "        wandb.log({\"percentage_pruned\":0})\n",
    "    tot_a+=a\n",
    "    tot_b+=b\n",
    "    dev_ppl,dev_loss=lstmModel.evaluate_ppl(model,dev_data,128)\n",
    "    print(children[k],dev_ppl,b)\n",
    "    wandb.log({\"dev_ppl\": dev_ppl})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_a,tot_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_a/tot_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
