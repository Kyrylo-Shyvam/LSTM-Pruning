{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5a7de5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:08.533665Z",
     "iopub.status.busy": "2023-11-02T17:12:08.533374Z",
     "iopub.status.idle": "2023-11-02T17:12:37.731483Z",
     "shell.execute_reply": "2023-11-02T17:12:37.730391Z"
    },
    "papermill": {
     "duration": 29.206251,
     "end_time": "2023-11-02T17:12:37.733914",
     "exception": false,
     "start_time": "2023-11-02T17:12:08.527663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LSTM-Pruning'...\r\n",
      "remote: Enumerating objects: 268, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (54/54), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 268 (delta 37), reused 50 (delta 37), pack-reused 214\u001b[K\r\n",
      "Receiving objects: 100% (268/268), 483.75 MiB | 22.85 MiB/s, done.\r\n",
      "Resolving deltas: 100% (126/126), done.\r\n",
      "Updating files: 100% (39/39), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone -b experiments https://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@github.com/Kyrylo-Shyvam/LSTM-Pruning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cbb5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:37.750508Z",
     "iopub.status.busy": "2023-11-02T17:12:37.750179Z",
     "iopub.status.idle": "2023-11-02T17:12:38.682833Z",
     "shell.execute_reply": "2023-11-02T17:12:38.681743Z"
    },
    "papermill": {
     "duration": 0.943466,
     "end_time": "2023-11-02T17:12:38.685059",
     "exception": false,
     "start_time": "2023-11-02T17:12:37.741593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM-Pruning  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224987d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:38.701079Z",
     "iopub.status.busy": "2023-11-02T17:12:38.700690Z",
     "iopub.status.idle": "2023-11-02T17:12:38.707605Z",
     "shell.execute_reply": "2023-11-02T17:12:38.706515Z"
    },
    "papermill": {
     "duration": 0.017236,
     "end_time": "2023-11-02T17:12:38.709606",
     "exception": false,
     "start_time": "2023-11-02T17:12:38.692370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/LSTM-Pruning/code\n"
     ]
    }
   ],
   "source": [
    "%cd ./LSTM-Pruning/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905b143b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:38.725231Z",
     "iopub.status.busy": "2023-11-02T17:12:38.724922Z",
     "iopub.status.idle": "2023-11-02T17:12:39.659055Z",
     "shell.execute_reply": "2023-11-02T17:12:39.658142Z"
    },
    "papermill": {
     "duration": 0.944592,
     "end_time": "2023-11-02T17:12:39.661460",
     "exception": false,
     "start_time": "2023-11-02T17:12:38.716868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md    batch.sh  iwslt2014_ende.zip  lstmModel.py     scripts   vocab.py\r\n",
      "__pycache__  data      lstmModel.ipynb\t   multi-bleu.perl  utils.py  work_dir\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429a184c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:39.677783Z",
     "iopub.status.busy": "2023-11-02T17:12:39.677471Z",
     "iopub.status.idle": "2023-11-02T17:12:40.610794Z",
     "shell.execute_reply": "2023-11-02T17:12:40.609835Z"
    },
    "papermill": {
     "duration": 0.944015,
     "end_time": "2023-11-02T17:12:40.612983",
     "exception": false,
     "start_time": "2023-11-02T17:12:39.668968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./work_dir/model0.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./work_dir/model0.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0dbcfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:40.629341Z",
     "iopub.status.busy": "2023-11-02T17:12:40.629029Z",
     "iopub.status.idle": "2023-11-02T17:12:41.566053Z",
     "shell.execute_reply": "2023-11-02T17:12:41.564728Z"
    },
    "papermill": {
     "duration": 0.947946,
     "end_time": "2023-11-02T17:12:41.568503",
     "exception": false,
     "start_time": "2023-11-02T17:12:40.620557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv ./work_dir/model0.bin ./work_dir/model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6259d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:41.585776Z",
     "iopub.status.busy": "2023-11-02T17:12:41.585050Z",
     "iopub.status.idle": "2023-11-02T17:12:42.516758Z",
     "shell.execute_reply": "2023-11-02T17:12:42.515823Z"
    },
    "papermill": {
     "duration": 0.942607,
     "end_time": "2023-11-02T17:12:42.518802",
     "exception": false,
     "start_time": "2023-11-02T17:12:41.576195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md   model.bin\tmodel2.bin  model4.bin\r\n",
      "decode.txt  model1.bin\tmodel3.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./work_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a222e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:42.535298Z",
     "iopub.status.busy": "2023-11-02T17:12:42.535006Z",
     "iopub.status.idle": "2023-11-02T17:12:43.466050Z",
     "shell.execute_reply": "2023-11-02T17:12:43.465011Z"
    },
    "papermill": {
     "duration": 0.941657,
     "end_time": "2023-11-02T17:12:43.468240",
     "exception": false,
     "start_time": "2023-11-02T17:12:42.526583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md    batch.sh  iwslt2014_ende.zip  lstmModel.py     scripts   vocab.py\r\n",
      "__pycache__  data      lstmModel.ipynb\t   multi-bleu.perl  utils.py  work_dir\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98debb7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:43.484917Z",
     "iopub.status.busy": "2023-11-02T17:12:43.484613Z",
     "iopub.status.idle": "2023-11-02T17:12:48.827277Z",
     "shell.execute_reply": "2023-11-02T17:12:48.826383Z"
    },
    "papermill": {
     "duration": 5.353887,
     "end_time": "2023-11-02T17:12:48.829767",
     "exception": false,
     "start_time": "2023-11-02T17:12:43.475880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import lstmModel\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5bd218b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:48.848664Z",
     "iopub.status.busy": "2023-11-02T17:12:48.848309Z",
     "iopub.status.idle": "2023-11-02T17:12:49.250127Z",
     "shell.execute_reply": "2023-11-02T17:12:49.249309Z"
    },
    "papermill": {
     "duration": 0.414134,
     "end_time": "2023-11-02T17:12:49.252677",
     "exception": false,
     "start_time": "2023-11-02T17:12:48.838543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=lstmModel.NMT.load('./work_dir/model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc96b0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:49.269439Z",
     "iopub.status.busy": "2023-11-02T17:12:49.269096Z",
     "iopub.status.idle": "2023-11-02T17:12:51.596003Z",
     "shell.execute_reply": "2023-11-02T17:12:51.595170Z"
    },
    "papermill": {
     "duration": 2.337526,
     "end_time": "2023-11-02T17:12:51.598021",
     "exception": false,
     "start_time": "2023-11-02T17:12:49.260495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"14dded5f079435f64fb5e2f0278662dda5605f9e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed767cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:51.615236Z",
     "iopub.status.busy": "2023-11-02T17:12:51.614898Z",
     "iopub.status.idle": "2023-11-02T17:12:51.619202Z",
     "shell.execute_reply": "2023-11-02T17:12:51.618386Z"
    },
    "papermill": {
     "duration": 0.015055,
     "end_time": "2023-11-02T17:12:51.621098",
     "exception": false,
     "start_time": "2023-11-02T17:12:51.606043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentages=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "types=['class-blind','class-uniform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999f694f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:12:51.637923Z",
     "iopub.status.busy": "2023-11-02T17:12:51.637680Z",
     "iopub.status.idle": "2023-11-02T18:33:05.908923Z",
     "shell.execute_reply": "2023-11-02T18:33:05.908175Z"
    },
    "papermill": {
     "duration": 4814.282099,
     "end_time": "2023-11-02T18:33:05.911010",
     "exception": false,
     "start_time": "2023-11-02T17:12:51.628911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvanshikadhingra1030\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_171253-3nvsj1tk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-energy-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/3nvsj1tk\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:17<00:00, 49.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.2827584910389831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.28276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrimson-energy-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/3nvsj1tk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_171253-3nvsj1tk/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_171554-6xvkyag0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meternal-butterfly-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/6xvkyag0\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:17<00:00, 49.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.28309628139288956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.2831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33meternal-butterfly-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/6xvkyag0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_171554-6xvkyag0/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_171853-8abqnbzi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mscarlet-wood-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/8abqnbzi\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:18<00:00, 48.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.28224545985576316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.28225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mscarlet-wood-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/8abqnbzi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_171853-8abqnbzi/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_172152-k1assogo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwinter-violet-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/k1assogo\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:17<00:00, 48.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.2823610030995167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.28236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mwinter-violet-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/k1assogo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_172152-k1assogo/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_172452-y5lgnhi9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-frost-13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/y5lgnhi9\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:18<00:00, 48.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.2787533814696365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.27875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mupbeat-frost-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/y5lgnhi9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_172452-y5lgnhi9/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_172752-kz0w9qx8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvital-pine-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/kz0w9qx8\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:18<00:00, 48.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.2779726866900786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.27797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvital-pine-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/kz0w9qx8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_172752-kz0w9qx8/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_173050-haaekeih\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswift-eon-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/haaekeih\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:20<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.26903420646950277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.26903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mswift-eon-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/haaekeih\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_173050-haaekeih/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_173352-hkif82i4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrose-spaceship-16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/hkif82i4\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:20<00:00, 48.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.26404511650645635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.26405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrose-spaceship-16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/hkif82i4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_173352-hkif82i4/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_173655-8tjh5xj7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mapricot-cloud-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/8tjh5xj7\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:23<00:00, 47.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.24538306633093818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.24538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mapricot-cloud-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/8tjh5xj7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_173655-8tjh5xj7/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_174000-23ud48ge\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhopeful-aardvark-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/23ud48ge\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:24<00:00, 46.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.2385148820005845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.23851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhopeful-aardvark-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/23ud48ge\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_174000-23ud48ge/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_174305-pgsyc7as\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgolden-blaze-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/pgsyc7as\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:27<00:00, 45.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.20242019234340833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.20242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgolden-blaze-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/pgsyc7as\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_174305-pgsyc7as/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_174612-pkn0mmr8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbright-cosmos-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/pkn0mmr8\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:29<00:00, 45.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.18533441900954462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.18533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbright-cosmos-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/pkn0mmr8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_174612-pkn0mmr8/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_174923-k6gdvg35\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlemon-yogurt-21\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/k6gdvg35\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [02:57<00:00, 38.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.11124294979842257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.11124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlemon-yogurt-21\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/k6gdvg35\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_174923-k6gdvg35/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_175302-927m5gvb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgallant-fire-22\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/927m5gvb\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [03:01<00:00, 37.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.09826420948796036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.09826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgallant-fire-22\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/927m5gvb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_175302-927m5gvb/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_175645-slfnq93b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myoung-firebrand-23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/slfnq93b\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [04:29<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.02003113017107615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.02003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myoung-firebrand-23\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/slfnq93b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_175645-slfnq93b/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_180156-zhly4i5t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33matomic-violet-24\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/zhly4i5t\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [08:14<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 0.00789193767097017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.00789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33matomic-violet-24\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/zhly4i5t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_180156-zhly4i5t/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_181054-iud1w8ha\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnoble-morning-25\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/iud1w8ha\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [10:24<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 8.938970201746278e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 9e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mnoble-morning-25\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/iud1w8ha\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_181054-iud1w8ha/logs\u001b[0m\n",
      "save model parameters to [./work_dir/model.bin.pruned]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LSTM-Pruning/code/wandb/run-20231102_182203-ocesk0da\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mskilled-sea-26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/ocesk0da\u001b[0m\n",
      "load test source sentences from [./data/test.de-en.de]\n",
      "load test target sentences from [./data/test.de-en.en]\n",
      "load model from ./work_dir/model.bin.pruned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 6750/6750 [10:24<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "Corpus BLEU: 0.0020298453314221503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bleu 0.00203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mskilled-sea-26\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vanshikadhingra1030/ablation/runs/ocesk0da\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231102_182203-ocesk0da/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for p in percentages:\n",
    "    for t in types:\n",
    "        lstmModel.pruneFunction({'MODEL_PATH':'./work_dir/model.bin',\n",
    "                                 'PRUNING_TYPE': t,\n",
    "                                 'PERCENTAGE': p})\n",
    "        wandb.init(project=\"ablation\")\n",
    "        wandb.config.pruningType = t\n",
    "        wandb.config.percentage = p\n",
    "        bleu = lstmModel.decode({\n",
    "            '--beam-size': '5',\n",
    "            '--cuda': 'True',\n",
    "            '--max-decoding-time-step': '100',\n",
    "            'MODEL_PATH': './work_dir/model.bin.pruned',\n",
    "            'TEST_SOURCE_FILE': './data/test.de-en.de',\n",
    "            'TEST_TARGET_FILE': './data/test.de-en.en',\n",
    "            'OUTPUT_FILE': './work_dir/decode.txt'\n",
    "        })\n",
    "        wandb.log({\"bleu\": bleu})\n",
    "        \n",
    "        # Finish the run for this combination of p and t\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee44846",
   "metadata": {
    "papermill": {
     "duration": 2.185869,
     "end_time": "2023-11-02T18:33:10.269746",
     "exception": false,
     "start_time": "2023-11-02T18:33:08.083877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4870.630033,
   "end_time": "2023-11-02T18:33:15.901874",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-02T17:12:05.271841",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
